# ============================================================
# LiteLLM Configuration - Support 100+ LLM Providers
# ============================================================

# ------------------------------
# Primary LLM Providers
# ------------------------------

# OpenAI API Key (REQUIRED for OpenAI models: gpt-4o, gpt-4o-mini, etc.)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (OPTIONAL for Claude models: claude-3-5-sonnet, claude-3-opus, etc.)
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Groq API Key (OPTIONAL for fast inference: llama-3.1-70b, mixtral-8x7b, etc.)
# Get from: https://console.groq.com/keys
# Note: Free tier available with rate limits
GROQ_API_KEY=your-groq-api-key-here

# Google Gemini API Key (OPTIONAL for Gemini models: gemini-1.5-pro, gemini-1.5-flash, etc.)
# Get from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# ------------------------------
# Cloud Platform LLM Providers
# ------------------------------

# Azure OpenAI (OPTIONAL for Azure-hosted OpenAI models)
# Get from: https://portal.azure.com
AZURE_API_KEY=your-azure-api-key-here
AZURE_API_BASE=https://your-resource.openai.azure.com
AZURE_API_VERSION=2024-02-15-preview

# AWS Bedrock (OPTIONAL for Claude, Llama, etc. via AWS)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=us-east-1

# Google Vertex AI (OPTIONAL for Gemini, PaLM via Google Cloud)
VERTEX_PROJECT=your-gcp-project-id
VERTEX_LOCATION=us-central1

# ------------------------------
# Other LLM Providers (OPTIONAL)
# ------------------------------

# Cohere API Key (for command-r-plus, command-r, etc.)
# Get from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=your-cohere-api-key-here

# Mistral API Key (for mistral-large, mistral-medium, etc.)
# Get from: https://console.mistral.ai/api-keys
MISTRAL_API_KEY=your-mistral-api-key-here

# Together AI API Key (for open-source models)
# Get from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=your-together-api-key-here

# HuggingFace API Key (for Inference API)
# Get from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your-huggingface-api-key-here

# Replicate API Key (for cloud-hosted models)
# Get from: https://replicate.com/account/api-tokens
REPLICATE_API_KEY=your-replicate-api-key-here

# ------------------------------
# Search & External APIs
# ------------------------------

# Serper API Key (REQUIRED for web search in fact-checking)
# Get from: https://serper.dev/api-key
SERPER_API_KEY=your-serper-api-key-here

# ------------------------------
# Application Settings
# ------------------------------

# Default LLM Model Configuration
# Model format: provider/model-name
# Popular options:
#   - openai/gpt-4o-mini          (fast, cheap: $0.15/1M tokens)
#   - openai/gpt-4o               (best quality: $5/1M tokens)
#   - anthropic/claude-3-5-sonnet-20241022  (high quality: $3/1M tokens)
#   - groq/llama-3.1-70b-versatile (free tier, ultra fast)
#   - gemini/gemini-1.5-flash     (cheap: $0.075/1M tokens)
DEFAULT_MODEL_NAME=openai/gpt-4o-mini
DEFAULT_TEMPERATURE=0.5
DEFAULT_MAX_TOKENS=2048

# Random Seed (for reproducibility)
RANDOM_SEED=1

# LiteLLM Debug Mode (OPTIONAL - set to DEBUG for detailed logs)
# LITELLM_LOG=DEBUG

# Proxy Settings (OPTIONAL)
# HTTP_PROXY=http://proxy:8080
# HTTPS_PROXY=https://proxy:8080
